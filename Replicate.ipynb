{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plaban1981/Stable_Diffusion_codes/blob/main/Replicate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Started with Replicate\n",
        "This notebook shows how to run models on [Replicate](https://replicate.com).\n",
        "\n",
        "Last updated: 2023-04-24"
      ],
      "metadata": {
        "id": "UXa9IwkeokWH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">[Run a model from Python](#updateTitle=true&folderId=18DKj1jLZ00WQAwMRuIYM22n5yGpZzb1r&scrollTo=UXa9IwkeokWH)\n",
        "\n",
        ">[Setup](#updateTitle=true&folderId=18DKj1jLZ00WQAwMRuIYM22n5yGpZzb1r&scrollTo=ep0A2pLDnoWK)\n",
        "\n",
        ">[Run a model](#updateTitle=true&folderId=18DKj1jLZ00WQAwMRuIYM22n5yGpZzb1r&scrollTo=Ax6xbVZOpnaV)\n",
        "\n",
        ">[Run a model in the background](#updateTitle=true&folderId=18DKj1jLZ00WQAwMRuIYM22n5yGpZzb1r&scrollTo=xLvskaxwtswn)\n",
        "\n",
        ">[Run a model in the background and get a webhook](#updateTitle=true&folderId=18DKj1jLZ00WQAwMRuIYM22n5yGpZzb1r&scrollTo=X7ZZHjNrunwr)\n",
        "\n",
        ">[Compose models into a pipeline](#updateTitle=true&folderId=18DKj1jLZ00WQAwMRuIYM22n5yGpZzb1r&scrollTo=xyfeLTILu3ad)\n",
        "\n",
        ">[Get streaming output from a running model](#updateTitle=true&folderId=18DKj1jLZ00WQAwMRuIYM22n5yGpZzb1r&scrollTo=WM47DByLrk5l)\n",
        "\n",
        ">[Cancel a prediction](#updateTitle=true&folderId=18DKj1jLZ00WQAwMRuIYM22n5yGpZzb1r&scrollTo=K7kZwHzLwWoM)\n",
        "\n",
        ">[Load output files](#updateTitle=true&folderId=18DKj1jLZ00WQAwMRuIYM22n5yGpZzb1r&scrollTo=5cuMDPg1xjQZ)\n",
        "\n",
        ">[Next steps](#updateTitle=true&folderId=18DKj1jLZ00WQAwMRuIYM22n5yGpZzb1r&scrollTo=vz6FASGXsefP)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "0rJP51rc6p3r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "To run this notebook, you’ll need to create a [Replicate](https://replicate.com) account and install the Replicate python client."
      ],
      "metadata": {
        "id": "ep0A2pLDnoWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install replicate client\n",
        "!pip install replicate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLTW6u8LnkDg",
        "outputId": "0709535e-4ce4-4a33-c344-85d070146a09"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting replicate\n",
            "  Downloading replicate-0.15.4-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from replicate) (23.2)\n",
            "Requirement already satisfied: pydantic>1 in /usr/local/lib/python3.10/dist-packages (from replicate) (1.10.13)\n",
            "Collecting httpx<1,>=0.21.0 (from replicate)\n",
            "  Downloading httpx-0.25.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (2023.7.22)\n",
            "Collecting httpcore<0.19.0,>=0.18.0 (from httpx<1,>=0.21.0->replicate)\n",
            "  Downloading httpcore-0.18.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>1->replicate) (4.5.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.19.0,>=0.18.0->httpx<1,>=0.21.0->replicate) (3.7.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore<0.19.0,>=0.18.0->httpx<1,>=0.21.0->replicate)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.19.0,>=0.18.0->httpx<1,>=0.21.0->replicate) (1.1.3)\n",
            "Installing collected packages: h11, httpcore, httpx, replicate\n",
            "Successfully installed h11-0.14.0 httpcore-0.18.0 httpx-0.25.0 replicate-0.15.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get a token: https://replicate.com/account\n",
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "REPLICATE_API_TOKEN = getpass()\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = REPLICATE_API_TOKEN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZTkrAUhoIJE",
        "outputId": "b487ce1c-1994-462b-9ac2-ed191d7e07d8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run a model\n",
        "You can run any public model on Replicate from your Python code. The following example runs [stability-ai/stable-diffusion](https://replicate.com/stability-ai/stable-diffusion):"
      ],
      "metadata": {
        "id": "Ax6xbVZOpnaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import replicate\n",
        "\n",
        "output = replicate.run(\n",
        "  \"stability-ai/stable-diffusion:27b93a2413e7f36cd83da926f3656280b2931564ff050bf9575f1fdf9bcd7478\",\n",
        "  input={\"prompt\": \"an iguana on the beach, pointillism\"}\n",
        ")\n",
        "\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQCcYU6_nXub",
        "outputId": "335a5fb6-c61c-47e5-d979-28b6bd127675"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://pbxt.replicate.delivery/p3I9vqi6I66WKtAy2Q3a1B3FYKhEj7dOdH4ePYAgMfEPiavRA/out-0.png']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image(url=output[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "l2sNBQg-pywR",
        "outputId": "fe41ba3d-e7c6-4648-c379-3d55f9e38bc8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://pbxt.replicate.delivery/p3I9vqi6I66WKtAy2Q3a1B3FYKhEj7dOdH4ePYAgMfEPiavRA/out-0.png\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = replicate.run(\n",
        "    \"logerzhu/ad-inpaint:b1c17d148455c1fda435ababe9ab1e03bc0d917cc3cf4251916f22c45c83c7df\",\n",
        "    input={\"image_path\": open(\"/content/139517568.jpg\", \"rb\"),\n",
        "    \"prompt\":\"shoe placed on a stone + waterfalls + wildernesss\",\n",
        "    \"negative_prompt\":\"illustration, 3d, sepia, painting, cartoons, sketch, worst quality:2)\",\n",
        "    \"api_key\":\"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\"}\n",
        ")\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyc2KNF7XNc5",
        "outputId": "cb5d7b55-557c-4b50-c965-864aef3fddee"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://pbxt.replicate.delivery/cyj5aMA8Ko4JH5TEUR5deMykvvDmQ23XjoDMCSZ6WW9RVt3IA/top.png', 'https://pbxt.replicate.delivery/MVJtNnagBZpxHNyMXLrrPlelyLzNFflguyJYTj8OMxRjqavRA/ad_inpaint_0.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url=output[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QjnGLTvIXtPK",
        "outputId": "d922fbb2-fdbf-472a-8138-3240263c8492"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://pbxt.replicate.delivery/MVJtNnagBZpxHNyMXLrrPlelyLzNFflguyJYTj8OMxRjqavRA/ad_inpaint_0.jpg\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url=output[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hqlAApP1ZXmM",
        "outputId": "6250cef2-9914-49d3-ec6f-f3ee4bd9a84a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://pbxt.replicate.delivery/cyj5aMA8Ko4JH5TEUR5deMykvvDmQ23XjoDMCSZ6WW9RVt3IA/top.png\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = output[0]\n",
        "output = replicate.run(\n",
        "    \"logerzhu/ad-inpaint:b1c17d148455c1fda435ababe9ab1e03bc0d917cc3cf4251916f22c45c83c7df\",\n",
        "    input={\"image_path\": \"https://pbxt.replicate.delivery/cyj5aMA8Ko4JH5TEUR5deMykvvDmQ23XjoDMCSZ6WW9RVt3IA/top.png\",\n",
        "    \"prompt\":\"shoe placed on a stone + waterfalls + wildernesss\",\n",
        "    \"negative_prompt\":\"illustration, 3d, sepia, painting, cartoons, sketch, worst quality:2)\",\n",
        "    \"api_key\":\"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\",\n",
        "    \"image_num\":4}\n",
        ")\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_-woKsMZ6d9",
        "outputId": "bde87708-7ef1-4379-bb61-ccb2ae55dfa8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://pbxt.replicate.delivery/IekFVHp5IITnViRYnVblIZ70mk6xZseefUjhioy0JDG6As9GB/top.png', 'https://pbxt.replicate.delivery/a4JpTMzyvi70Adx68mlzrf45bW4oj5N4lKEouzGROzePAbvRA/ad_inpaint_0.jpg', 'https://pbxt.replicate.delivery/GSzRDvbOL74QEl1JbsKeMHq8TQV5sauoFXjzc4cgmmtHgt3IA/ad_inpaint_1.jpg', 'https://pbxt.replicate.delivery/jkQue7grps2gBakXlTFwiAaioyjHSZuj7NtJEIUv0RePAbvRA/ad_inpaint_2.jpg', 'https://pbxt.replicate.delivery/es0a324lsEViIqt2hdb4vSi8HLlFJf2ROAeFPljoTesfBY7NC/ad_inpaint_3.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OutImage Generated"
      ],
      "metadata": {
        "id": "P0dWzLugf4de"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url=output[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1OHuIP8oex0Z",
        "outputId": "74c687d3-d854-47a2-9758-68acbc588ced"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://pbxt.replicate.delivery/IekFVHp5IITnViRYnVblIZ70mk6xZseefUjhioy0JDG6As9GB/top.png\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url=output[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yu_ULyG7e3Cg",
        "outputId": "a75c9cd3-b0e9-4562-c2af-7e01ae9e46ac"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://pbxt.replicate.delivery/a4JpTMzyvi70Adx68mlzrf45bW4oj5N4lKEouzGROzePAbvRA/ad_inpaint_0.jpg\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url=output[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rJyxVTbUe6yM",
        "outputId": "2306e5bd-8641-43e1-bd78-26456211844f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://pbxt.replicate.delivery/GSzRDvbOL74QEl1JbsKeMHq8TQV5sauoFXjzc4cgmmtHgt3IA/ad_inpaint_1.jpg\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url=output[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rJHJ-3E2e-t0",
        "outputId": "2fcd2d39-20c5-4477-ff07-9aa4f4083633"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://pbxt.replicate.delivery/jkQue7grps2gBakXlTFwiAaioyjHSZuj7NtJEIUv0RePAbvRA/ad_inpaint_2.jpg\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Original Input image"
      ],
      "metadata": {
        "id": "oZ4ZtFZTfzYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url=\"https://worthly.com/wp-content/uploads/2014/11/139517568.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6GkED-_7fYni",
        "outputId": "2d40581d-fd31-4bbd-c9b2-fbcc9a54ed36"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://worthly.com/wp-content/uploads/2014/11/139517568.jpg\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some models receive images as inputs. To pass a file as an input, use a file handle or URL:"
      ],
      "metadata": {
        "id": "zUZBwKOYqozu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# image = open(\"mystery.jpg\", \"rb\")\n",
        "# or...\n",
        "# image = \"https://example.com/mystery.jpg\"\n",
        "#\n",
        "# for this example, let's use the URL from the previous prediction:\n",
        "image = output[0]\n",
        "\n",
        "replicate.run(\n",
        "  \"andreasjansson/blip-2:4b32258c42e9efd4288bb9910bc532a69727f9acd26aa08e175713a0a857a608\",\n",
        "  input={\"image\": output[0], \"prompt\": \"what's in this picture?\"}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NaQ3Jytoqyk5",
        "outputId": "d02626a1-cde4-4e24-ef1f-d1cf80621507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'an iguana'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run a model in the background\n",
        "You can start a model and run it in the background:"
      ],
      "metadata": {
        "id": "xLvskaxwtswn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = replicate.models.get(\"stability-ai/stablelm-tuned-alpha-7b\")\n",
        "version = model.versions.get(\"c49dae362cbaecd2ceabb5bd34fdb68413c4ff775111fea065d259d577757beb\")\n",
        "\n",
        "prediction = replicate.predictions.create(\n",
        "    version=version,\n",
        "    input={\"prompt\":\"How do you make ratatouille?\"})"
      ],
      "metadata": {
        "id": "v0SlZt3Otx6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIA6_2auuFe2",
        "outputId": "d97c465c-3394-4460-bd54-a9c25e36886b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Prediction(id='z6shxqlg5zg5fj4ytqbydcifni', error=None, input={'prompt': 'How do you make ratatouille?'}, logs=None, output=None, status='starting', version=Version(id='c49dae362cbaecd2ceabb5bd34fdb68413c4ff775111fea065d259d577757beb', created_at=datetime.datetime(2023, 4, 20, 23, 7, 42, 348263, tzinfo=datetime.timezone.utc), cog_version='0.7.0-beta17', openapi_schema={'info': {'title': 'Cog', 'version': '0.1.0'}, 'paths': {'/': {'get': {'summary': 'Root', 'responses': {'200': {'content': {'application/json': {'schema': {'title': 'Response Root  Get'}}}, 'description': 'Successful Response'}}, 'operationId': 'root__get'}}, '/shutdown': {'post': {'summary': 'Start Shutdown', 'responses': {'200': {'content': {'application/json': {'schema': {'title': 'Response Start Shutdown Shutdown Post'}}}, 'description': 'Successful Response'}}, 'operationId': 'start_shutdown_shutdown_post'}}, '/predictions': {'post': {'summary': 'Predict', 'responses': {'200': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PredictionResponse'}}}, 'description': 'Successful Response'}, '422': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}, 'description': 'Validation Error'}}, 'parameters': [{'in': 'header', 'name': 'prefer', 'schema': {'type': 'string', 'title': 'Prefer'}, 'required': False}], 'description': 'Run a single prediction on the model', 'operationId': 'predict_predictions_post', 'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PredictionRequest'}}}}}}, '/health-check': {'get': {'summary': 'Healthcheck', 'responses': {'200': {'content': {'application/json': {'schema': {'title': 'Response Healthcheck Health Check Get'}}}, 'description': 'Successful Response'}}, 'operationId': 'healthcheck_health_check_get'}}, '/predictions/{prediction_id}': {'put': {'summary': 'Predict Idempotent', 'responses': {'200': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PredictionResponse'}}}, 'description': 'Successful Response'}, '422': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}, 'description': 'Validation Error'}}, 'parameters': [{'in': 'path', 'name': 'prediction_id', 'schema': {'type': 'string', 'title': 'Prediction ID'}, 'required': True}, {'in': 'header', 'name': 'prefer', 'schema': {'type': 'string', 'title': 'Prefer'}, 'required': False}], 'description': 'Run a single prediction on the model (idempotent creation).', 'operationId': 'predict_idempotent_predictions__prediction_id__put', 'requestBody': {'content': {'application/json': {'schema': {'allOf': [{'$ref': '#/components/schemas/PredictionRequest'}], 'title': 'Prediction Request'}}}, 'required': True}}}, '/predictions/{prediction_id}/cancel': {'post': {'summary': 'Cancel', 'responses': {'200': {'content': {'application/json': {'schema': {'title': 'Response Cancel Predictions  Prediction Id  Cancel Post'}}}, 'description': 'Successful Response'}, '422': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}, 'description': 'Validation Error'}}, 'parameters': [{'in': 'path', 'name': 'prediction_id', 'schema': {'type': 'string', 'title': 'Prediction ID'}, 'required': True}], 'description': 'Cancel a running prediction', 'operationId': 'cancel_predictions__prediction_id__cancel_post'}}}, 'openapi': '3.0.2', 'components': {'schemas': {'Input': {'type': 'object', 'title': 'Input', 'properties': {'top_p': {'type': 'number', 'title': 'Top P', 'default': 1, 'maximum': 1, 'minimum': 0.01, 'x-order': 2, 'description': 'Valid if you choose top_p decoding. When decoding text, samples from the top p percentage of most likely tokens; lower to ignore less likely tokens'}, 'prompt': {'type': 'string', 'title': 'Prompt', 'default': \"What's your mood today?\", 'x-order': 0, 'description': 'Input Prompt.'}, 'max_tokens': {'type': 'integer', 'title': 'Max Tokens', 'default': 100, 'minimum': 1, 'x-order': 1, 'description': 'Maximum number of tokens to generate. A word is generally 2-3 tokens'}, 'temperature': {'type': 'number', 'title': 'Temperature', 'default': 0.75, 'maximum': 5, 'minimum': 0.01, 'x-order': 3, 'description': 'Adjusts randomness of outputs, greater than 1 is random and 0 is deterministic, 0.75 is a good starting value.'}, 'repetition_penalty': {'type': 'number', 'title': 'Repetition Penalty', 'default': 1.2, 'maximum': 5, 'minimum': 0.01, 'x-order': 4, 'description': 'Penalty for repeated words in generated text; 1 is no penalty, values greater than 1 discourage repetition, less than 1 encourage it.'}}}, 'Output': {'type': 'array', 'items': {'type': 'string'}, 'title': 'Output', 'x-cog-array-type': 'iterator', 'x-cog-array-display': 'concatenate'}, 'Status': {'enum': ['starting', 'processing', 'succeeded', 'canceled', 'failed'], 'type': 'string', 'title': 'Status', 'description': 'An enumeration.'}, 'WebhookEvent': {'enum': ['start', 'output', 'logs', 'completed'], 'type': 'string', 'title': 'WebhookEvent', 'description': 'An enumeration.'}, 'ValidationError': {'type': 'object', 'title': 'ValidationError', 'required': ['loc', 'msg', 'type'], 'properties': {'loc': {'type': 'array', 'items': {'anyOf': [{'type': 'string'}, {'type': 'integer'}]}, 'title': 'Location'}, 'msg': {'type': 'string', 'title': 'Message'}, 'type': {'type': 'string', 'title': 'Error Type'}}}, 'PredictionRequest': {'type': 'object', 'title': 'PredictionRequest', 'properties': {'id': {'type': 'string', 'title': 'Id'}, 'input': {'$ref': '#/components/schemas/Input'}, 'webhook': {'type': 'string', 'title': 'Webhook', 'format': 'uri', 'maxLength': 65536, 'minLength': 1}, 'created_at': {'type': 'string', 'title': 'Created At', 'format': 'date-time'}, 'output_file_prefix': {'type': 'string', 'title': 'Output File Prefix'}, 'webhook_events_filter': {'type': 'array', 'items': {'$ref': '#/components/schemas/WebhookEvent'}, 'default': ['output', 'logs', 'completed', 'start'], 'uniqueItems': True}}}, 'PredictionResponse': {'type': 'object', 'title': 'PredictionResponse', 'properties': {'id': {'type': 'string', 'title': 'Id'}, 'logs': {'type': 'string', 'title': 'Logs', 'default': ''}, 'error': {'type': 'string', 'title': 'Error'}, 'input': {'$ref': '#/components/schemas/Input'}, 'output': {'$ref': '#/components/schemas/Output'}, 'status': {'$ref': '#/components/schemas/Status'}, 'metrics': {'type': 'object', 'title': 'Metrics'}, 'version': {'type': 'string', 'title': 'Version'}, 'created_at': {'type': 'string', 'title': 'Created At', 'format': 'date-time'}, 'started_at': {'type': 'string', 'title': 'Started At', 'format': 'date-time'}, 'completed_at': {'type': 'string', 'title': 'Completed At', 'format': 'date-time'}}}, 'HTTPValidationError': {'type': 'object', 'title': 'HTTPValidationError', 'properties': {'detail': {'type': 'array', 'items': {'$ref': '#/components/schemas/ValidationError'}, 'title': 'Detail'}}}}}}), started_at=None, created_at='2023-04-24T19:30:15.981984Z', completed_at=None)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction.status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oJ5Mll-JuPXl",
        "outputId": "baac8390-52ea-4dc9-ee48-3a055e613ab2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'starting'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict(prediction).keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owP4pydEuQ-A",
        "outputId": "772f641f-6673-4eaa-da15-b3fd5acc0bc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['id', 'error', 'input', 'logs', 'output', 'status', 'version', 'started_at', 'created_at', 'completed_at'])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction.reload()"
      ],
      "metadata": {
        "id": "q6rKX8e7uXRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction.status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eLma8KgJuZ9t",
        "outputId": "1a8edd8b-2987-434b-8f26-683901835962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'succeeded'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''.join(prediction.output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "DIdTadrBujYZ",
        "outputId": "881f6468-0590-437e-bca0-44188801d998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There are many ways! Here’s one common recipe:  First, start with fresh tomatoes; then heat them up without washing or peeling them first -- this can take several hours depending on how ripe they are. Next add some herbs like thyme leaves only, about two handfuls of parsley at most, for flavor as well as texture. Then let it simmer gently until “bubbles” form around the edges of your pan. This should have taken 15 – 30 minutes total. The'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run a model in the background and get a webhook"
      ],
      "metadata": {
        "id": "X7ZZHjNrunwr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can run a model and get a webhook when it completes, instead of waiting for it to finish.\n",
        "\n",
        "If you're working locally, we'd recommend using [ngrok](https://ngrok.com/download) for debugging webhooks. It allows you to tunnel your localhost to a public domain."
      ],
      "metadata": {
        "id": "Y264GRLRuyW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = replicate.models.get(\"kvfrans/clipdraw\")\n",
        "version = model.versions.get(\"5797a99edc939ea0e9242d5e8c9cb3bc7d125b1eac21bda852e5cb79ede2cd9b\")\n",
        "prediction = replicate.predictions.create(\n",
        "    version=version,\n",
        "    input={\"prompt\":\"Watercolor painting of an underwater submarine\"},\n",
        "    webhook=\"https://example.com/your-webhook\",\n",
        "    webhook_events_filter=[\"completed\"]\n",
        ")"
      ],
      "metadata": {
        "id": "G7iH_9-Lum69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compose models into a pipeline\n",
        "You can run a model and feed the output into another model:"
      ],
      "metadata": {
        "id": "xyfeLTILu3ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# laionide = replicate.models.get(\"afiaka87/laionide-v4\").versions.get(\"b21cbe271e65c1718f2999b038c18b45e21e4fba961181fbfae9342fc53b9e05\")\n",
        "# swinir = replicate.models.get(\"jingyunliang/swinir\").versions.get(\"660d922d33153019e8c263a3bba265de882e7f4f70396546b6c9c8f9d47a021a\")\n",
        "# image = laionide.predict(prompt=\"avocado armchair\")\n",
        "# upscaled_image = swinir.predict(image=image)"
      ],
      "metadata": {
        "id": "Z9VNlqEtu-X5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GXqf8OmTu-EG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get streaming output from a running model\n",
        "Some models stream output as the model is running. They will return an iterator, and you can iterate over that output:"
      ],
      "metadata": {
        "id": "WM47DByLrk5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iterator = replicate.run(\n",
        "  \"replicate/dolly-v2-12b:ef0e1aefc61f8e096ebe4db6b2bacc297daf2ef6899f0f7e001ec445893500e5\",\n",
        "  input={\"prompt\": \"Who was Dolly the sheep?\"},\n",
        ")\n",
        "for text in iterator:\n",
        "      print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkjJKac8rlS2",
        "outputId": "ab07ed31-8d04-4710-8b4b-47222bcec419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dolly\n",
            " the\n",
            " sheep\n",
            " was\n",
            " a\n",
            " sheep\n",
            " that\n",
            " belonged\n",
            " to\n",
            " Ian\n",
            " Wilmut\n",
            " and\n",
            " Robert\n",
            " Douglas\n",
            " at\n",
            " The\n",
            " Roslin\n",
            " belonged\n",
            " to\n",
            " Ian\n",
            " Wilmut\n",
            " and\n",
            " Robert\n",
            " Douglas\n",
            " at\n",
            " The\n",
            " Roslin\n",
            " Institute\n",
            " in\n",
            " Scotland.  In\n",
            " 1997,\n",
            " Dolly\n",
            " was\n",
            " the\n",
            " first\n",
            " successfully\n",
            " cloned\n",
            " mammal.\n",
            " She\n",
            " gave\n",
            " sheep\n",
            " that\n",
            " belonged\n",
            " to\n",
            " Ian\n",
            " Wilmut\n",
            " and\n",
            " Robert\n",
            " Douglas\n",
            " at\n",
            " The\n",
            " Roslin\n",
            " Institute\n",
            " in\n",
            " Scotland.  In\n",
            " 1997,\n",
            " Dolly\n",
            " was\n",
            " the\n",
            " first\n",
            " successfully\n",
            " cloned\n",
            " mammal.\n",
            " She\n",
            " gave\n",
            " birth\n",
            " to\n",
            " five\n",
            " clones\n",
            " between\n",
            " 1998\n",
            " and\n",
            " 2003.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cancel a prediction\n",
        "You can cancel a running prediction:"
      ],
      "metadata": {
        "id": "K7kZwHzLwWoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = replicate.models.get(\"cjwbw/damo-text-to-video\")\n",
        "version = model.versions.get(\"1e205ea73084bd17a0a3b43396e49ba0d6bc2e754e9283b2df49fad2dcf95755\")\n",
        "\n",
        "prediction = replicate.predictions.create(\n",
        "    version=version,\n",
        "    input={\"prompt\":\"How do you make ratatouille?\"})"
      ],
      "metadata": {
        "id": "YryIQVJ7wWHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction.status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zwVtyEVLw4o_",
        "outputId": "53c09862-56f7-4be3-9ad2-e819e689ab2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'starting'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction.cancel()"
      ],
      "metadata": {
        "id": "BME9JCeNw5qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction.reload()"
      ],
      "metadata": {
        "id": "inuDz8Dtw6ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction.status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NRZbHkXNw8jJ",
        "outputId": "aaf507ee-eb01-4f4f-9429-cf4c25867c4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'canceled'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = replicate.predictions.list()\n",
        "\n",
        "[p.status for p in predictions[:10]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PV0EnN4xFf5",
        "outputId": "fd630777-a4ef-4aa2-985a-ba304ea482b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['succeeded',\n",
              " 'processing',\n",
              " 'succeeded',\n",
              " 'succeeded',\n",
              " 'succeeded',\n",
              " 'succeeded',\n",
              " 'succeeded',\n",
              " 'succeeded',\n",
              " 'succeeded',\n",
              " 'succeeded']"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load output files\n",
        "Output files are returned as HTTPS URLs. You can load an output file as a buffer:"
      ],
      "metadata": {
        "id": "5cuMDPg1xjQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlretrieve\n",
        "\n",
        "model = replicate.models.get(\"stability-ai/stable-diffusion\")\n",
        "version = model.versions.get(\"27b93a2413e7f36cd83da926f3656280b2931564ff050bf9575f1fdf9bcd7478\")\n",
        "out = version.predict(prompt=\"wavy colorful abstract patterns, cgsociety\")\n",
        "urlretrieve(out[0], \"/tmp/out.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTcA8OGYxmCe",
        "outputId": "bc5336ae-098d-42ec-9e12-b5f4f2cf483c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/tmp/out.png', <http.client.HTTPMessage at 0x7fbf0bf21370>)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Next steps\n",
        "\n",
        "- Explore our collection of hosted [models](https://replicate.com/explore)\n",
        "\n",
        "\n",
        "\n",
        "- Learn about how to integrate with [LangChain](https://python.langchain.com/en/latest/modules/models/llms/integrations/replicate.html)\n",
        "\n",
        "\n",
        "\n",
        "- Note that you can also run models with the raw HTTP API. Refer to the [HTTP API reference](https://replicate.com/docs/reference/http) for more details."
      ],
      "metadata": {
        "id": "vz6FASGXsefP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yzRipDfdyu_D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}